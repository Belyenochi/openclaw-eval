"""
EDD é—­ç¯å‘½ä»¤

è´Ÿè´£ï¼š
- suggest: ä»å¤±è´¥ cases ç”Ÿæˆä¿®æ”¹å»ºè®®
- apply: åº”ç”¨å»ºè®®åˆ° workspace
- diff: å¯¹æ¯”ä¸¤æ¬¡ run çš„å˜åŒ–
- mine: ä»å†å²æ—¥å¿—æŒ–æ˜ golden cases
- export: å¯¼å‡º golden datasetï¼ˆJSONL æ ¼å¼ï¼‰
"""

import csv
import difflib
import json
import sys
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path

from .tracer import read_all_logs, extract_events, get_workspace, _is_turn_end, sessions_from_logs


# ============================================================================
# suggest å‘½ä»¤
# ============================================================================

def analyze_failure(result: dict, workspace: Path) -> dict:
    """åˆ†æå¤±è´¥åŸå› ï¼Œç”Ÿæˆå»ºè®®"""
    case_id = result["case"]["id"]
    message = result["case"]["message"]
    failures = result.get("failures", [])
    tool_names = result.get("tool_names", [])

    suggestion = {
        "case_id": case_id,
        "message": message,
        "failures": failures,
        "recommendations": []
    }

    for failure in failures:
        if "ç¼ºå°‘å¿…è¦å·¥å…·è°ƒç”¨" in failure:
            # æå–ç¼ºå¤±çš„å·¥å…·
            import re
            match = re.search(r"'(\w+)'", failure)
            if match:
                missing_tool = match.group(1)

                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº” skill
                skills_dir = workspace / "skills"
                skill_file = skills_dir / f"{missing_tool}.md"

                if skill_file.exists():
                    suggestion["recommendations"].append({
                        "type": "modify_skill",
                        "file": f"skills/{missing_tool}.md",
                        "action": f"è¡¥å……å·¥å…·è°ƒç”¨æ­¥éª¤ï¼š{missing_tool}"
                    })
                else:
                    suggestion["recommendations"].append({
                        "type": "create_skill",
                        "file": f"skills/{case_id}.md",
                        "action": f"æ–°å»º skillï¼ŒåŒ…å«å·¥å…·è°ƒç”¨ï¼š{missing_tool}"
                    })

        elif "å·¥å…·è°ƒç”¨é¡ºåºä¸ç¬¦" in failure:
            suggestion["recommendations"].append({
                "type": "modify_skill",
                "file": f"skills/{case_id}.md",
                "action": "è°ƒæ•´å·¥å…·è°ƒç”¨é¡ºåº"
            })

        elif "è°ƒç”¨äº†ç¦æ­¢çš„å·¥å…·" in failure:
            suggestion["recommendations"].append({
                "type": "modify_tools",
                "file": "TOOLS.md",
                "action": "åœ¨ä½¿ç”¨çº¦å®šä¸­æ·»åŠ ç¦æ­¢è§„åˆ™"
            })

        elif "è¾“å‡ºç¼ºå°‘å…³é”®è¯" in failure:
            suggestion["recommendations"].append({
                "type": "modify_skill",
                "file": f"skills/{case_id}.md",
                "action": "è¡¥å……è¾“å‡ºæ ¼å¼è¦æ±‚"
            })

        elif "å·¥å…·å‚æ•°ä¸ç¬¦" in failure:
            # æå–å·¥å…·åå’Œå‚æ•°ä¿¡æ¯
            import re
            match = re.search(r"å·¥å…·å‚æ•°ä¸ç¬¦: (\w+)\.(\w+) æœŸæœ›=(\S+) å®é™…=(\S+)", failure)
            if match:
                tool_name, arg_key, expected, actual = match.groups()
                suggestion["recommendations"].append({
                    "type": "modify_skill",
                    "file": f"skills/{case_id}.md",
                    "action": f"åœ¨ skill æ–‡ä»¶é‡Œæ˜ç¡®å·¥å…·è°ƒç”¨å‚æ•°ï¼š{tool_name} åº”ä½¿ç”¨ {arg_key}={expected}"
                })

    return suggestion


def cmd_suggest(args):
    """Suggest å‘½ä»¤å…¥å£"""
    if not Path(args.report).exists():
        print(f"âœ— æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {args.report}")
        sys.exit(1)

    with open(args.report, 'r', encoding='utf-8') as f:
        results = json.load(f)

    workspace = get_workspace(args.workspace)
    failed_results = [r for r in results if not r.get("passed", False)]

    if not failed_results:
        print("âœ“ æ‰€æœ‰ç”¨ä¾‹é€šè¿‡ï¼Œæ— éœ€å»ºè®®")
        return

    print(f"ğŸ“‹ åˆ†æ {len(failed_results)} ä¸ªå¤±è´¥ç”¨ä¾‹\n")

    for result in failed_results:
        suggestion = analyze_failure(result, workspace)
        
        print(f"=== case: {suggestion['case_id']} ===")
        print(f"æ¶ˆæ¯: {suggestion['message']}")
        for failure in suggestion['failures']:
            print(f"å¤±è´¥åŸå› : {failure}")
        
        for rec in suggestion['recommendations']:
            print(f"å»ºè®®æ–‡ä»¶: {rec['file']}")
            print(f"å»ºè®®å†…å®¹: {rec['action']}")
        
        print("â”€" * 60)
        print()


# ============================================================================
# apply å‘½ä»¤
# ============================================================================

READONLY_FILES = {"SOUL.md", "AGENTS.md", "USER.md", "BOOTSTRAP.md", "IDENTITY.md"}


def apply_suggestion(suggestion: dict, workspace: Path, auto_yes: bool = False):
    """åº”ç”¨å•ä¸ªå»ºè®®"""
    for rec in suggestion['recommendations']:
        file_path = workspace / rec['file']
        
        # æ£€æŸ¥åªè¯»æ–‡ä»¶
        if file_path.name in READONLY_FILES:
            print(f"[SKIP] {file_path.name} ä¸ºåªè¯»æ–‡ä»¶ï¼Œè¯·æ‰‹åŠ¨ä¿®æ”¹")
            print(f"å»ºè®®å†…å®¹: {rec['action']}")
            continue

        # ç”Ÿæˆä¿®æ”¹å†…å®¹
        if rec['type'] == 'create_skill':
            content = f"""# {suggestion['case_id']}

## è§¦å‘æ¡ä»¶
{suggestion['message']}

## æ­¥éª¤
1. {rec['action']}

## è¾“å‡ºæ ¼å¼
åŒ…å«ç›¸å…³ä¿¡æ¯çš„è‡ªç„¶è¯­è¨€å›å¤
"""
            if file_path.exists():
                print(f"[SKIP] {file_path} å·²å­˜åœ¨")
                continue

            # æ˜¾ç¤º diff
            print(f"\n[CREATE] {file_path}")
            print(content)

            if not auto_yes:
                confirm = input("ç¡®è®¤åˆ›å»º? (y/n): ")
                if confirm.lower() != 'y':
                    print("[SKIP]")
                    continue

            # åŸå­å†™
            file_path.parent.mkdir(parents=True, exist_ok=True)
            tmp_file = file_path.with_suffix('.tmp')
            with open(tmp_file, 'w', encoding='utf-8') as f:
                f.write(content)
            tmp_file.rename(file_path)
            print(f"âœ“ å·²åˆ›å»º: {file_path}")

        elif rec['type'] == 'modify_tools':
            if not file_path.exists():
                print(f"[SKIP] {file_path} ä¸å­˜åœ¨")
                continue

            with open(file_path, 'r', encoding='utf-8') as f:
                original = f.read()

            # æŸ¥æ‰¾"## ä½¿ç”¨çº¦å®š" section
            if "## ä½¿ç”¨çº¦å®š" in original:
                new_content = original + f"\n- {rec['action']}\n"
            else:
                new_content = original + f"\n\n## ä½¿ç”¨çº¦å®š\n- {rec['action']}\n"

            # æ˜¾ç¤º diff
            print(f"\n[MODIFY] {file_path}")
            diff = difflib.unified_diff(
                original.splitlines(keepends=True),
                new_content.splitlines(keepends=True),
                fromfile=str(file_path),
                tofile=str(file_path)
            )
            print(''.join(diff))

            if not auto_yes:
                confirm = input("ç¡®è®¤ä¿®æ”¹? (y/n): ")
                if confirm.lower() != 'y':
                    print("[SKIP]")
                    continue

            # åŸå­å†™
            tmp_file = file_path.with_suffix('.tmp')
            with open(tmp_file, 'w', encoding='utf-8') as f:
                f.write(new_content)
            tmp_file.rename(file_path)
            print(f"âœ“ å·²ä¿®æ”¹: {file_path}")


def cmd_apply(args):
    """Apply å‘½ä»¤å…¥å£"""
    if not Path(args.suggestion_file).exists():
        print(f"âœ— å»ºè®®æ–‡ä»¶ä¸å­˜åœ¨: {args.suggestion_file}")
        sys.exit(1)

    # è§£æå»ºè®®æ–‡ä»¶ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”è¯¥è§£æ suggest çš„è¾“å‡ºï¼‰
    print("âš  apply å‘½ä»¤éœ€è¦é…åˆ suggest è¾“å‡ºä½¿ç”¨")
    print("å½“å‰ç‰ˆæœ¬ä¸ºç®€åŒ–å®ç°")


# ============================================================================
# diff å‘½ä»¤
# ============================================================================

def cmd_diff(args):
    """Diff å‘½ä»¤å…¥å£"""
    if not Path(args.before).exists() or not Path(args.after).exists():
        print("âœ— æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")
        sys.exit(1)

    with open(args.before, 'r', encoding='utf-8') as f:
        before_results = json.load(f)
    with open(args.after, 'r', encoding='utf-8') as f:
        after_results = json.load(f)

    # è®¡ç®—æ•´ä½“æŒ‡æ ‡
    before_passed = sum(1 for r in before_results if r.get("passed", False))
    after_passed = sum(1 for r in after_results if r.get("passed", False))
    before_rate = before_passed / len(before_results) * 100 if before_results else 0
    after_rate = after_passed / len(after_results) * 100 if after_results else 0

    before_avg = sum(r.get("duration_s", 0) for r in before_results) / len(before_results) if before_results else 0
    after_avg = sum(r.get("duration_s", 0) for r in after_results) / len(after_results) if after_results else 0

    print("ğŸ“Š EDD Diff")
    print(f"baseline : {args.before}")
    print(f"new      : {args.after}")
    print("â”€" * 60)

    # æŒ‰ eval_type åˆ†ç»„ç»Ÿè®¡
    before_regression = [r for r in before_results if r.get("case", {}).get("eval_type", "regression") == "regression"]
    after_regression = [r for r in after_results if r.get("case", {}).get("eval_type", "regression") == "regression"]
    before_capability = [r for r in before_results if r.get("case", {}).get("eval_type", "regression") == "capability"]
    after_capability = [r for r in after_results if r.get("case", {}).get("eval_type", "regression") == "capability"]

    if before_regression or after_regression:
        before_reg_rate = (sum(1 for r in before_regression if r.get("passed", False)) / len(before_regression) * 100) if before_regression else 0
        after_reg_rate = (sum(1 for r in after_regression if r.get("passed", False)) / len(after_regression) * 100) if after_regression else 0
        delta_reg = after_reg_rate - before_reg_rate
        symbol_reg = "âœ“" if delta_reg >= 0 else "âœ—"
        print(f"Regression: {before_reg_rate:.0f}% â†’ {after_reg_rate:.0f}% {symbol_reg} ({delta_reg:+.0f}%)")

    if before_capability or after_capability:
        before_cap_rate = (sum(1 for r in before_capability if r.get("passed", False)) / len(before_capability) * 100) if before_capability else 0
        after_cap_rate = (sum(1 for r in after_capability if r.get("passed", False)) / len(after_capability) * 100) if after_capability else 0
        delta_cap = after_cap_rate - before_cap_rate
        symbol_cap = "âœ“" if delta_cap >= 0 else "âœ—"
        print(f"Capability: {before_cap_rate:.0f}% â†’ {after_cap_rate:.0f}% {symbol_cap} ({delta_cap:+.1f}%)")

    print()
    print(f"Pass rate:  {before_rate:.0f}% â†’ {after_rate:.0f}%  ({after_rate - before_rate:+.0f}%)")
    print(f"è€—æ—¶:       {before_avg:.1f}s â†’ {after_avg:.1f}s  ({after_avg - before_avg:+.1f}s)")
    print()

    # æŒ‰ case_id å¯¹æ¯”
    before_map = {r["case"]["id"]: r for r in before_results}
    after_map = {r["case"]["id"]: r for r in after_results}

    for case_id in set(before_map.keys()) | set(after_map.keys()):
        before = before_map.get(case_id)
        after = after_map.get(case_id)

        if not before:
            print(f"{case_id}   NEW")
        elif not after:
            print(f"{case_id}   REMOVED")
        else:
            before_status = "PASS" if before.get("passed") else "FAIL"
            after_status = "PASS" if after.get("passed") else "FAIL"

            if before_status != after_status:
                symbol = "âœ“" if after_status == "PASS" else "âœ—"
                print(f"{case_id}   {before_status} â†’ {after_status}  {symbol}")

                # å·¥å…·é“¾å˜åŒ–
                before_tools = before.get("tool_names", [])
                after_tools = after.get("tool_names", [])
                if before_tools != after_tools:
                    print(f"  å·¥å…·é“¾: {before_tools} â†’ {after_tools}")

                # å¤±è´¥åŸå› å˜åŒ–
                before_failures = before.get("failures", [])
                after_failures = after.get("failures", [])
                if before_failures and not after_failures:
                    print(f"  å¤±è´¥åŸå› æ¶ˆå¤±: {before_failures[0]}")
                elif after_failures and not before_failures:
                    print(f"  æ–°å¢å¤±è´¥åŸå› : {after_failures[0]}")
            else:
                print(f"{case_id}   {before_status} â†’ {after_status}  (unchanged)")


# ============================================================================
# mine å‘½ä»¤
# ============================================================================

def cmd_mine(args):
    """Mine å‘½ä»¤å…¥å£"""
    from .tracer import LOG_DIR, sessions_from_logs, read_logs_for_session, extract_events

    log_dir = Path(args.log_dir) if args.log_dir else LOG_DIR

    # ä½¿ç”¨ç´¢å¼•è·å–æ‰€æœ‰ sessionsï¼ˆæ”¯æŒå¤§æ–‡ä»¶ï¼‰
    print("ğŸ“¦ æ‰«ææ—¥å¿—æ–‡ä»¶...")
    all_sessions = sessions_from_logs(log_dir)

    if not all_sessions:
        print("âœ— æœªæ‰¾åˆ° session")
        return

    # è¿‡æ»¤æˆåŠŸçš„ session
    successful_sessions = []
    for session in all_sessions:
        if session["tool_count"] >= args.min_tools and session["turns"] > 0:
            successful_sessions.append(session)

    if not successful_sessions:
        print("âœ— æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ session")
        return

    print(f"ğŸ“¦ ä» {len(successful_sessions)} ä¸ª session æå–ç”¨ä¾‹")

    # è¯»å–å·²æœ‰ casesï¼ˆå»é‡ï¼‰
    existing_messages = set()
    output_file = Path(args.output) if args.output else Path("mined_cases.yaml")
    if output_file.exists():
        try:
            import yaml
            with open(output_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                if data and "cases" in data:
                    for case in data.get("cases", []):
                        existing_messages.add(case.get("message", ""))
        except:
            pass

    # æå–æ–° cases
    new_cases = []
    for session in successful_sessions:
        session_id = session["session_id"]

        # è¯»å–è¯¥ session çš„æ—¥å¿—
        entries = read_logs_for_session(log_dir, session_id)
        events = extract_events(entries, session_id)

        # æå– message
        message = None
        for entry in entries:
            if "user_message" in entry:
                message = entry["user_message"]
                break
            elif "input" in entry and isinstance(entry["input"], str):
                message = entry["input"]
                break
            elif "prompt" in entry:
                message = entry["prompt"]
                break

        if not message or message in existing_messages:
            continue

        # æå–å·¥å…·åºåˆ—
        tool_names = [e.tool for e in events if e.kind == "tool_end"]

        case = {
            "id": f"mined_{session_id[:8]}",
            "message": message,
            "expect_tools": list(dict.fromkeys(tool_names)),  # å»é‡ä¿åº
            "expect_tools_ordered": tool_names,
            "tags": ["mined"],
            "description": f"ä» session {session_id[:8]} æå–ï¼Œæ—¶é—´ {session['last_ts'][:10]}"
        }

        new_cases.append(case)
        existing_messages.add(message)

    if not new_cases:
        print("âœ“ æ²¡æœ‰æ–°çš„ cases éœ€è¦æ·»åŠ ")
        return

    # å†™å…¥æ–‡ä»¶
    output_data = {"cases": new_cases}

    try:
        import yaml
        with open(output_file, 'w', encoding='utf-8') as f:
            yaml.dump(output_data, f, allow_unicode=True, default_flow_style=False)
        print(f"âœ“ å·²ç”Ÿæˆ {len(new_cases)} ä¸ªç”¨ä¾‹: {output_file}")
    except ImportError:
        print("âœ— éœ€è¦å®‰è£… PyYAML: pip install pyyaml")
        sys.exit(1)


# ============================================================================
# export å‘½ä»¤
# ============================================================================

def cmd_export(args):
    """Export å‘½ä»¤å…¥å£ - å¯¼å‡º golden dataset"""
    from .tracer import LOG_DIR, read_all_logs, _is_tool_end, _is_turn_end

    log_dir = Path(args.log_dir) if args.log_dir else LOG_DIR
    workspace = get_workspace(args.workspace)

    # è¯»å–æ—¥å¿—ï¼ˆä¼šè‡ªåŠ¨è·³è¿‡å¤§æ–‡ä»¶ï¼‰
    print("ğŸ“¦ æ‰«ææ—¥å¿—æ–‡ä»¶...")
    entries = read_all_logs(log_dir)

    if not entries:
        print("âœ— æœªæ‰¾åˆ°æ—¥å¿—æ¡ç›®")
        return

    # æ‰‹åŠ¨èšåˆ sessions
    sessions_dict = defaultdict(lambda: {
        "session_id": "",
        "first_ts": "",
        "last_ts": "",
        "tool_count": 0,
        "turns": 0,
        "agent": "",
    })

    for entry in entries:
        session_id = entry.get("session_id", "")
        if not session_id:
            continue

        session = sessions_dict[session_id]
        session["session_id"] = session_id

        ts = entry.get("ts", "")
        if not session["first_ts"] or ts < session["first_ts"]:
            session["first_ts"] = ts
        if not session["last_ts"] or ts > session["last_ts"]:
            session["last_ts"] = ts

        if _is_tool_end(entry):
            session["tool_count"] += 1

        if _is_turn_end(entry):
            session["turns"] += 1

        if not session["agent"] and "agent" in entry:
            session["agent"] = entry["agent"]

    sessions = list(sessions_dict.values())

    # åŠ è½½ merge reportï¼ˆå¦‚æœæœ‰ï¼‰
    merge_data = {}
    if args.merge_report and Path(args.merge_report).exists():
        with open(args.merge_report, 'r', encoding='utf-8') as f:
            report_results = json.load(f)
            for r in report_results:
                if r.get("passed"):
                    message = r["case"]["message"]
                    merge_data[message] = r.get("final_output", "")

    # è¿‡æ»¤æˆåŠŸçš„ session
    successful_sessions = [s for s in sessions if s["tool_count"] >= args.min_tools and s["turns"] > 0]

    if not successful_sessions:
        print("âœ— æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ session")
        return

    print(f"ğŸ“¦ ä» {len(successful_sessions)} ä¸ª session å¯¼å‡º golden dataset")

    # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰ session çš„æ•°æ®å¹¶æŒ‰ skill åˆ†ç»„
    session_data_list = []
    skill_to_tools = defaultdict(set)  # skill_triggered -> è¯¥ skill ä¸‹æ‰€æœ‰ session ç”¨è¿‡çš„å·¥å…·é›†åˆ

    for session in successful_sessions:
        session_id = session["session_id"]

        # è¯»å–è¯¥ session çš„æ—¥å¿—
        from .tracer import read_logs_for_session
        entries = read_logs_for_session(log_dir, session_id)
        events = extract_events(entries, session_id)

        # æå– user message
        user_message = None
        for entry in entries:
            for key in ["user_message", "input", "prompt"]:
                if key in entry and isinstance(entry[key], str):
                    user_message = entry[key]
                    break
            if user_message:
                break

        if not user_message:
            continue

        # æ„å»º golden_tool_sequence
        golden_tools = []
        for event in events:
            if event.kind == "tool_end":
                golden_tools.append({
                    "name": event.tool,
                    "args": event.input,
                    "output_summary": event.output[:200] if event.output else ""
                })

        # è·å– golden_output
        golden_output = ""
        golden_output_source = "log"
        for event in reversed(events):
            if event.kind == "llm_response":
                golden_output = event.output
                break

        # å°è¯•ä» merge report è·å–æ›´å‡†ç¡®çš„è¾“å‡º
        if user_message in merge_data:
            golden_output = merge_data[user_message]
            golden_output_source = "report"

        # åŒ¹é… skill
        tool_names = [t["name"] for t in golden_tools]
        skill_triggered = None
        skills_dir = workspace / "skills"
        if skills_dir.exists():
            for skill_file in skills_dir.glob("*.md"):
                skill_name = skill_file.stem.replace("_", "").replace("-", "")
                for tool in tool_names:
                    tool_clean = tool.replace("_", "").replace("-", "")
                    if skill_name in tool_clean or tool_clean in skill_name:
                        skill_triggered = f"skills/{skill_file.name}"
                        break
                if skill_triggered:
                    break

        # è®°å½•æ•°æ®
        session_data = {
            "session": session,
            "session_id": session_id,
            "user_message": user_message,
            "golden_tools": golden_tools,
            "tool_names": tool_names,
            "golden_output": golden_output,
            "golden_output_source": golden_output_source,
            "skill_triggered": skill_triggered
        }
        session_data_list.append(session_data)

        # æŒ‰ skill åˆ†ç»„æ”¶é›†å·¥å…·
        skill_key = skill_triggered if skill_triggered else "__no_skill__"
        skill_to_tools[skill_key].update(tool_names)

    # ç¬¬äºŒéï¼šç”Ÿæˆ recordsï¼ŒåŒ…å« not_tool_called
    records = []
    for session_data in session_data_list:
        session_id = session_data["session_id"]
        session = session_data["session"]
        user_message = session_data["user_message"]
        golden_tools = session_data["golden_tools"]
        tool_names = session_data["tool_names"]
        golden_output = session_data["golden_output"]
        golden_output_source = session_data["golden_output_source"]
        skill_triggered = session_data["skill_triggered"]

        # ç”Ÿæˆ assert
        asserts = []
        for tool in tool_names:
            asserts.append({"type": "tool_called", "value": tool})
        if len(tool_names) > 1:
            asserts.append({"type": "tool_order", "value": tool_names, "strict": False})

        # ç”Ÿæˆ tool_args æ–­è¨€
        for tool_data in golden_tools:
            if tool_data["args"]:
                asserts.append({
                    "type": "tool_args",
                    "tool": tool_data["name"],
                    "args": tool_data["args"]
                })

        # ç®€å•è¯é¢‘æå–å…³é”®è¯
        if golden_output:
            words = golden_output.split()
            word_freq = Counter(w for w in words if len(w) > 2)
            top_keywords = [w for w, _ in word_freq.most_common(3)]
            for kw in top_keywords:
                asserts.append({"type": "contains", "value": kw})

        # ç”Ÿæˆ not_tool_called
        skill_key = skill_triggered if skill_triggered else "__no_skill__"
        all_tools_in_skill = skill_to_tools[skill_key]

        # åªæœ‰å½“åŒç±» session æ•°é‡ > 1 æ—¶æ‰ç”Ÿæˆ not_tool_called
        if len([s for s in session_data_list if (s["skill_triggered"] if s["skill_triggered"] else "__no_skill__") == skill_key]) > 1:
            # åŒç±» session ç”¨è¿‡ä½†å½“å‰ session æ²¡ç”¨çš„å·¥å…·
            forbidden_tools = all_tools_in_skill - set(tool_names)
            for tool in sorted(forbidden_tools):
                asserts.append({"type": "not_tool_called", "value": tool})

        # æ„å»ºè®°å½•
        record = {
            "id": f"{session_id[:8]}_1",
            "description": f"ä» session {session_id[:8]} æå–ï¼Œ{session['last_ts'][:10]}",
            "source": "mined",
            "tags": ["mined"],
            "conversation": [
                {
                    "turn": 1,
                    "user": user_message,
                    "golden_tool_sequence": golden_tools,
                    "golden_output": golden_output,
                    "assert": asserts
                }
            ],
            "metadata": {
                "session_id": session_id,
                "agent": session.get("agent", "openclaw_agent"),
                "extracted_at": datetime.now().isoformat(),
                "skill_triggered": skill_triggered,
                "golden_output_source": golden_output_source
            }
        }

        records.append(record)

    # è¾“å‡º
    output_file = Path(args.output)

    if args.format == "csv":
        # CSV æ ¼å¼
        with open(output_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=[
                "id", "description", "user", "golden_tools", "golden_output",
                "skill_triggered", "session_id", "extracted_at"
            ])
            writer.writeheader()

            for record in records:
                conv = record["conversation"][0]
                tools_str = ", ".join(t["name"] for t in conv["golden_tool_sequence"])
                writer.writerow({
                    "id": record["id"],
                    "description": record["description"],
                    "user": conv["user"],
                    "golden_tools": tools_str,
                    "golden_output": conv["golden_output"][:200],
                    "skill_triggered": record["metadata"]["skill_triggered"] or "",
                    "session_id": record["metadata"]["session_id"],
                    "extracted_at": record["metadata"]["extracted_at"]
                })

        print(f"âœ“ å·²å¯¼å‡º {len(records)} æ¡è®°å½•åˆ° CSV: {output_file}")

    else:
        # JSONL æ ¼å¼
        with open(output_file, 'w', encoding='utf-8') as f:
            for record in records:
                f.write(json.dumps(record, ensure_ascii=False) + '\n')
        
        print(f"âœ“ å·²å¯¼å‡º {len(records)} æ¡è®°å½•åˆ° JSONL: {output_file}")


# ============================================================================
# ä¸»å…¥å£
# ============================================================================

def cmd_edd(args):
    """EDD å‘½ä»¤åˆ†å‘"""
    if args.edd_cmd == "suggest":
        cmd_suggest(args)
    elif args.edd_cmd == "apply":
        cmd_apply(args)
    elif args.edd_cmd == "diff":
        cmd_diff(args)
    elif args.edd_cmd == "mine":
        cmd_mine(args)
    elif args.edd_cmd == "judge":
        cmd_judge(args)
    elif args.edd_cmd == "export":
        cmd_export(args)


# ============================================================================
# judge å‘½ä»¤
# ============================================================================

def cmd_judge(args):
    """Judge å‘½ä»¤å…¥å£ - ç”¨ LLM å¯¹ tool é€‰æ‹©å’Œ output è´¨é‡æ‰“åˆ†"""
    import os

    report_path = Path(args.report)
    if not report_path.exists():
        print(f"âœ— æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {args.report}")
        sys.exit(1)

    with open(report_path, 'r', encoding='utf-8') as f:
        results = json.load(f)

    # åˆå§‹åŒ– LLM client
    provider = getattr(args, 'provider', 'anthropic')

    if provider == "anthropic":
        try:
            from anthropic import Anthropic
            api_key = os.environ.get("ANTHROPIC_API_KEY")
            if not api_key:
                print("âœ— æœªè®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
                sys.exit(1)
            client = Anthropic(api_key=api_key)
            client_type = "anthropic"
        except ImportError:
            print("âœ— éœ€è¦å®‰è£… anthropic: pip install anthropic")
            sys.exit(1)
    elif provider == "openai":
        try:
            from openai import OpenAI
            api_key = os.environ.get("OPENAI_API_KEY")
            if not api_key:
                print("âœ— æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
                sys.exit(1)
            client = OpenAI(api_key=api_key)
            client_type = "openai"
        except ImportError:
            print("âœ— éœ€è¦å®‰è£… openai: pip install openai")
            sys.exit(1)
    elif provider == "deepseek":
        try:
            from openai import OpenAI
            api_key = os.environ.get("DEEPSEEK_API_KEY")
            if not api_key:
                print("âœ— æœªè®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
                sys.exit(1)
            client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
            client_type = "openai"
        except ImportError:
            print("âœ— éœ€è¦å®‰è£… openai: pip install openai")
            sys.exit(1)
    else:
        print(f"âœ— ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
        sys.exit(1)

    print(f"ğŸ“Š ä½¿ç”¨ LLM è¯„ä¼° {len(results)} ä¸ªæµ‹è¯•ç»“æœ...")
    print(f"æä¾›å•†: {provider}")
    print(f"æ¨¡å‹: {args.model}\n")

    judged_results = []

    for i, result in enumerate(results, 1):
        case_id = result["case"]["id"]
        message = result["case"]["message"]
        tool_names = result.get("tool_names", [])
        final_output = result.get("final_output", "")
        passed = result.get("passed", False)

        print(f"[{i}/{len(results)}] è¯„ä¼° {case_id}...")

        # æ„å»º prompt
        prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹ AI Agent çš„æ‰§è¡Œç»“æœï¼š

ç”¨æˆ·è¾“å…¥: {message}

å·¥å…·è°ƒç”¨åºåˆ—: {tool_names}

æœ€ç»ˆè¾“å‡º: {final_output}

æµ‹è¯•çŠ¶æ€: {"é€šè¿‡" if passed else "å¤±è´¥"}

è¯·ä»ä»¥ä¸‹ç»´åº¦æ‰“åˆ†ï¼ˆ0-10åˆ†ï¼‰ï¼š
1. å·¥å…·é€‰æ‹©åˆç†æ€§ï¼šé€‰æ‹©çš„å·¥å…·æ˜¯å¦åˆé€‚ã€å¿…è¦
2. å·¥å…·è°ƒç”¨é¡ºåºï¼šå·¥å…·è°ƒç”¨çš„é¡ºåºæ˜¯å¦åˆç†
3. è¾“å‡ºè´¨é‡ï¼šè¾“å‡ºæ˜¯å¦å‡†ç¡®ã€å®Œæ•´ã€æœ‰ç”¨
4. æ•´ä½“è¡¨ç°ï¼šç»¼åˆè¯„ä»·

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{{
  "tool_selection_score": <0-10>,
  "tool_order_score": <0-10>,
  "output_quality_score": <0-10>,
  "overall_score": <0-10>,
  "reasoning": "<ç®€çŸ­è¯„ä»·>"
}}"""

        try:
            # è°ƒç”¨ LLM API
            if client_type == "anthropic":
                response = client.messages.create(
                    model=args.model,
                    max_tokens=1024,
                    messages=[
                        {"role": "user", "content": prompt}
                    ]
                )
                response_text = response.content[0].text
            else:  # openai or deepseek
                response = client.chat.completions.create(
                    model=args.model,
                    messages=[
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1024
                )
                response_text = response.choices[0].message.content

            # å°è¯•æå– JSON
            import re
            json_match = re.search(r'\{[^}]+\}', response_text, re.DOTALL)
            if json_match:
                judgment = json.loads(json_match.group(0))
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ° JSONï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                judgment = json.loads(response_text)

            result_copy = result.copy()
            result_copy["llm_judgment"] = {
                **judgment,
                "model": args.model,
                "provider": provider,
                "raw_response": response_text
            }
            judged_results.append(result_copy)

            print(f"  âœ“ ç»¼åˆå¾—åˆ†: {judgment.get('overall_score', 'N/A')}/10")

        except Exception as e:
            print(f"  âœ— è¯„ä¼°å¤±è´¥: {e}")
            result_copy = result.copy()
            result_copy["llm_judgment"] = {"error": str(e)}
            judged_results.append(result_copy)

    # è¾“å‡ºç»Ÿè®¡
    print("\n" + "â”€" * 60)
    print("ğŸ“Š è¯„ä¼°ç»Ÿè®¡")
    print("â”€" * 60)

    valid_judgments = [r for r in judged_results if "llm_judgment" in r and "overall_score" in r["llm_judgment"]]
    if valid_judgments:
        avg_overall = sum(r["llm_judgment"]["overall_score"] for r in valid_judgments) / len(valid_judgments)
        avg_tool_selection = sum(r["llm_judgment"]["tool_selection_score"] for r in valid_judgments) / len(valid_judgments)
        avg_tool_order = sum(r["llm_judgment"]["tool_order_score"] for r in valid_judgments) / len(valid_judgments)
        avg_output_quality = sum(r["llm_judgment"]["output_quality_score"] for r in valid_judgments) / len(valid_judgments)

        print(f"å¹³å‡ç»¼åˆå¾—åˆ†: {avg_overall:.1f}/10")
        print(f"å¹³å‡å·¥å…·é€‰æ‹©: {avg_tool_selection:.1f}/10")
        print(f"å¹³å‡å·¥å…·é¡ºåº: {avg_tool_order:.1f}/10")
        print(f"å¹³å‡è¾“å‡ºè´¨é‡: {avg_output_quality:.1f}/10")

    # ä¿å­˜ç»“æœ
    output_path = Path(args.output) if args.output else report_path.with_suffix('.judged.json')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(judged_results, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
